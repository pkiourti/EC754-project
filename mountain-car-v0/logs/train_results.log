[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.[0m
Saved model loaded from 'save/MountainCar-v0_target_model_1543419126.88.h5'
Starting testing.. Expecting reward to be -110 over 100 iterations
Iteration: 1	Score: -105.0
Iteration: 2	Score: -105.0
Iteration: 3	Score: -105.0
Iteration: 4	Score: -104.0
Iteration: 5	Score: -105.0
Iteration: 6	Score: -105.0
Iteration: 7	Score: -105.0
Iteration: 8	Score: -105.0
Iteration: 9	Score: -105.0
Iteration: 10	Score: -104.0
Iteration: 11	Score: -105.0
Iteration: 12	Score: -84.0
Iteration: 13	Score: -105.0
Iteration: 14	Score: -85.0
Iteration: 15	Score: -105.0
Iteration: 16	Score: -105.0
Iteration: 17	Score: -105.0
Iteration: 18	Score: -105.0
Iteration: 19	Score: -105.0
Iteration: 20	Score: -105.0
Iteration: 21	Score: -105.0
Iteration: 22	Score: -104.0
Iteration: 23	Score: -84.0
Iteration: 24	Score: -105.0
Iteration: 25	Score: -83.0
Iteration: 26	Score: -105.0
Iteration: 27	Score: -105.0
Iteration: 28	Score: -105.0
Iteration: 29	Score: -105.0
Iteration: 30	Score: -105.0
Iteration: 31	Score: -104.0
Iteration: 32	Score: -105.0
Iteration: 33	Score: -105.0
Iteration: 34	Score: -102.0
Iteration: 35	Score: -105.0
Iteration: 36	Score: -84.0
Iteration: 37	Score: -105.0
Iteration: 38	Score: -105.0
Iteration: 39	Score: -105.0
Iteration: 40	Score: -105.0
Iteration: 41	Score: -105.0
Iteration: 42	Score: -105.0
Iteration: 43	Score: -105.0
Iteration: 44	Score: -105.0
Iteration: 45	Score: -105.0
Iteration: 46	Score: -105.0
Iteration: 47	Score: -105.0
Iteration: 48	Score: -105.0
Iteration: 49	Score: -105.0
Iteration: 50	Score: -105.0
Iteration: 51	Score: -104.0
Iteration: 52	Score: -105.0
Iteration: 53	Score: -104.0
Iteration: 54	Score: -105.0
Iteration: 55	Score: -105.0
Iteration: 56	Score: -105.0
Iteration: 57	Score: -105.0
Iteration: 58	Score: -105.0
Iteration: 59	Score: -105.0
Iteration: 60	Score: -105.0
Iteration: 61	Score: -105.0
Iteration: 62	Score: -84.0
Iteration: 63	Score: -105.0
Iteration: 64	Score: -105.0
Iteration: 65	Score: -105.0
Iteration: 66	Score: -103.0
Iteration: 67	Score: -105.0
Iteration: 68	Score: -105.0
Iteration: 69	Score: -105.0
Iteration: 70	Score: -85.0
Iteration: 71	Score: -105.0
Iteration: 72	Score: -105.0
Iteration: 73	Score: -103.0
Iteration: 74	Score: -101.0
Iteration: 75	Score: -84.0
Iteration: 76	Score: -105.0
Iteration: 77	Score: -105.0
Iteration: 78	Score: -102.0
Iteration: 79	Score: -102.0
Iteration: 80	Score: -85.0
Iteration: 81	Score: -105.0
Iteration: 82	Score: -105.0
Iteration: 83	Score: -105.0
Iteration: 84	Score: -105.0
Iteration: 85	Score: -105.0
Iteration: 86	Score: -104.0
Iteration: 87	Score: -104.0
Iteration: 88	Score: -105.0
Iteration: 89	Score: -105.0
Iteration: 90	Score: -105.0
Iteration: 91	Score: -104.0
Iteration: 92	Score: -105.0
Iteration: 93	Score: -105.0
Iteration: 94	Score: -105.0
Iteration: 95	Score: -105.0
Iteration: 96	Score: -104.0
Iteration: 97	Score: -105.0
Iteration: 98	Score: -105.0
Iteration: 99	Score: -105.0
Iteration: 100	Score: -103.0
Total Avg. Score over 100 consecutive iterations : -102.84
Agent finished test within expected reward boundary! Environment is solved.
